{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Saver] 모델 저장하고 불러오기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 모델을 저장하고 불러오려면 두개의 파일이 필요\n",
    "\n",
    "  * **Meta garph**\n",
    "    - Tensorflow graph저장\n",
    "    - 모든 Variables, operations, collections 저장\n",
    "    - ** *.meta ** 의 확장자 파일\n",
    "<p></p>\n",
    "  * **Checkpoint file** \n",
    "    - binary 파일로 Weight, bias, gradients 등을 저장\n",
    "    - **model.ckpt.data-00000-of-00001, model.ckpt.index** 의 2가지 파일로 저장됨\n",
    "    - ** *.data** 파일은 _Training variable_ 을 가짐\n",
    "    - checkpoint 파일은 **최근 상태만 기록**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 모델 저장 방법 \n",
    "* 선언 : Weight, bias Variable 정의 직후에 선언하는것이 좋음 (그 이후에 넣으면 필요없는 Variable 까지 저장됨)\n",
    "<pre><code>\n",
    "saver = tf.train.Saver()\n",
    "</code></pre>\n",
    "* 저장 \n",
    "<pre><code>\n",
    "saver.save(sess, '모델저장 경로')\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tf.train.Saver.save\n",
    "<pre><code>\n",
    "save(\n",
    "    sess,\n",
    "    save_path,\n",
    "    global_step=None,\n",
    "    latest_filename=None,\n",
    "    meta_graph_suffix='meta',\n",
    "    write_meta_graph=True,\n",
    "    write_state=True,\n",
    "    strip_default_attrs=False,\n",
    "    save_debug_info=False\n",
    ")\n",
    "</code></pre>\n",
    "\n",
    "\n",
    "* ex) 모델 학습 1000 이후에 저장 하려면... **global_step** 파라미터를 사용\n",
    "<pre><code>\n",
    "saver.save(sess, 'my_test_model', global_step=1000)\n",
    "</code></pre>\n",
    "> 아래와 같은 모델 저장 파일이 생성됨 \n",
    "  * my_test_model-1000.index\n",
    "  * my_test_model-1000.meta\n",
    "  * my_test_model-1000.data-00000-of-00001\n",
    "  * checkpoint\n",
    "* ex) 정해진 학습 횟수마다 모델 저장하려면...\n",
    "<pre><code>\n",
    "#max_to_keep=5 => tf.train.Saver() 선언시 기본으로 최근 5개만 기록 하게 됨\n",
    "if step % 1000 == 0:\n",
    "    print(\"step : {}. cost : {}, accuracy : {}\".format(step, cost_val, acc_val))\n",
    "    # 학습이 1000번 수행 될때 마다 저장하며 그래프는 저장 안함\n",
    "    ckpt_path = saver.save(sess, save_file, step)\n",
    "    print(\"Save ckpt file : \",ckpt_path)\n",
    "</code></pre>\n",
    "\n",
    "* 모델의 구조는 학습하는 동안 변경되지 않으므로 **.meta** 파일은 저장하지 않도록 하려면... **write_meta_graph=False** 파리미터를 사용\n",
    "<pre><code>\n",
    "saver.save(sess, 'my_test_model', global_step=1000, write_meta_graph=False)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tf.train.Saver\n",
    "<pre><code>\n",
    "__init__(\n",
    "    var_list=None,\n",
    "    reshape=False,\n",
    "    sharded=False,\n",
    "    max_to_keep=5,\n",
    "    keep_checkpoint_every_n_hours=10000.0,\n",
    "    name=None,\n",
    "    restore_sequentially=False,\n",
    "    saver_def=None,\n",
    "    builder=None,\n",
    "    defer_build=False,\n",
    "    allow_empty=False,\n",
    "    write_version=tf.train.SaverDef.V2,\n",
    "    pad_step_number=False,\n",
    "    save_relative_paths=False,\n",
    "    filename=None\n",
    ")\n",
    "</code></pre>\n",
    "\n",
    "\n",
    "* max_to_keep => 학습시 특정 시점에 모델을 저장한 ckpt파일이 저장되는 갯수(default : 5)\n",
    "* max_to_keep=None or 0 일 경우 모두 저장함\n",
    "\n",
    "\n",
    "* ex) 최근 2시간동안 4개의 모델만 저장하려면...**max_to_keep, keep_checkpoint_every_n_hours** 파리미터 사용\n",
    "\n",
    "<pre><code>\n",
    "# saver 선언시 파라미터 입력\n",
    "saver = tf.train.Saver(max_to_keep=4, keep_checkpoint_every_n_hours=2)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```tf.train.Saver()``` 로 선언하면 모든 Variable을 저장함\n",
    "* ```tf.train.Saver(Variable//Collection 항목)``` 로 선언하면 Variable 항목만 저장하게됨\n",
    "* 저장할 Variable//Collection 항목은 list, dict 형태의 자료형을 사용가능함\n",
    "<pre><code>\n",
    "saver = tf.train.Saver([W1, W2, b1, b2])\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 읽어오기 위하여 2가지 작업을 해야함\n",
    "  1. 네트워크 생성\n",
    "    * **.meta** 파일을 불러옴\n",
    "    * ```tf.train.import()``` 함수를 이용함\n",
    "    * 저장된 네트워크를 불러오면 기존 네트워크에 이어서 붙게 됨\n",
    "    * ```tf.reset_default_graph()``` 를 실행하여 이전에 있던 그래프를 초기화 해줘야 불러오는 네트워크를 사용함\n",
    "  2. 파라미터 로딩\n",
    "    * ```tf.train.Saver()``` 를 이용해서 파라미터를 로딩 \n",
    "    * 가져올 Variable를 선언하고 그 값을 restore 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tf.train.Saver.restore\n",
    "<pre><code>\n",
    "restore(\n",
    "    sess,\n",
    "    save_path\n",
    ")\n",
    "</code></pre>\n",
    "\n",
    "###### tf.train.latest_checkpoint\n",
    "<pre><code>\n",
    "tf.train.latest_checkpoint(\n",
    "    checkpoint_dir,\n",
    "    latest_filename=None\n",
    ")\n",
    "</code></pre>\n",
    "* ex) 저장된 네트워크를 불러오고 값을 가져옴\n",
    "<pre><code>\n",
    "saver = tf.train.import_meta_graph('my-model-1000.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "</code></pre>\n",
    "\n",
    "* restore는 ```sess.run(tf.global_variables_initializer())``` 하는 부분에서 사용하며 초기화 하는 대신 저장된 데이터를 가져온다고 생각 하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 및 저장 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./my_test_model/my_test_model-1000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Prepare to feed input, i.e. feed_dict and placeholders\n",
    "w1 = tf.placeholder(tf.float32, name=\"w1\")\n",
    "w2 = tf.placeholder(tf.float32, name=\"w2\")\n",
    "b1 = tf.Variable(2.0,dtype=tf.float32, name=\"bias\")\n",
    "feed_dict = {'w1': 4.0, 'w2': 8.0}\n",
    "\n",
    "# Define a test operation that we will restore\n",
    "w3 = w1 + w2\n",
    "w4 = tf.multiply(w3, b1, name=\"op_to_restore\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Run the operation by feeding input\n",
    "result = sess.run(w4, {w1:feed_dict['w1'], w2:feed_dict['w2']})\n",
    "print(result)\n",
    "# Prints 24 which is sum of (w1+w2)*b1\n",
    "\n",
    "# Now, save the graph\n",
    "saver.save(sess, './my_test_model/my_test_model', global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 새로운 입력값으로 처리\n",
    "\n",
    "* placeholder 불러오기\n",
    "> graph.get_tensor_by_name()\n",
    "\n",
    "* operation 불러오기\n",
    "> graph.get_operation_by_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model/my_test_model-1000\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('./my_test_model/my_test_model-1000.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./my_test_model'))\n",
    "\n",
    "\n",
    "# Now, let's access and create placeholders variables and\n",
    "# create feed-dict to feed new data\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "feed_dict ={w1:13.0,w2:17.0}\n",
    "\n",
    "#Now, access the op that you want to run. \n",
    "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "print (sess.run(op_to_restore,feed_dict))\n",
    "#This will print 60 which is calculated \n",
    "#using new values of w1 and w2 and saved value of b1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 현재 graph에서 로딩 가능한 operation 종류 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1\n",
      "w2\n",
      "bias/initial_value\n",
      "bias\n",
      "bias/Assign\n",
      "bias/read\n",
      "add\n",
      "op_to_restore\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/restore_all\n",
      "Mul/y\n",
      "Mul\n",
      "w1_1\n",
      "w2_1\n",
      "bias_1/initial_value\n",
      "bias_1\n",
      "bias_1/Assign\n",
      "bias_1/read\n",
      "add_1\n",
      "op_to_restore_1\n",
      "init_1\n",
      "save/Const_1\n",
      "save/SaveV2_1/tensor_names\n",
      "save/SaveV2_1/shape_and_slices\n",
      "save/SaveV2_1\n",
      "save/control_dependency_1\n",
      "save/RestoreV2_1/tensor_names\n",
      "save/RestoreV2_1/shape_and_slices\n",
      "save/RestoreV2_1\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/restore_all_1\n",
      "w1_2\n",
      "w2_2\n",
      "bias/initial_value_1\n",
      "bias_2\n",
      "bias/Assign_1\n",
      "bias/read_1\n",
      "add_2\n",
      "op_to_restore_2\n",
      "init_2\n",
      "save/Const_2\n",
      "save/SaveV2/tensor_names_1\n",
      "save/SaveV2/shape_and_slices_1\n",
      "save/SaveV2_2\n",
      "save/control_dependency_2\n",
      "save/RestoreV2/tensor_names_1\n",
      "save/RestoreV2/shape_and_slices_1\n",
      "save/RestoreV2_2\n",
      "save/Assign_3\n",
      "save/restore_all_2\n",
      "Mul/y_1\n",
      "Mul_1\n",
      "w1_1_1\n",
      "w2_1_1\n",
      "bias_1/initial_value_1\n",
      "bias_1_1\n",
      "bias_1/Assign_1\n",
      "bias_1/read_1\n",
      "add_1_1\n",
      "op_to_restore_1_1\n",
      "init_1_1\n",
      "save/Const_1_1\n",
      "save/SaveV2_1/tensor_names_1\n",
      "save/SaveV2_1/shape_and_slices_1\n",
      "save/SaveV2_1_1\n",
      "save/control_dependency_1_1\n",
      "save/RestoreV2_1/tensor_names_1\n",
      "save/RestoreV2_1/shape_and_slices_1\n",
      "save/RestoreV2_1_1\n",
      "save/Assign_1_1\n",
      "save/Assign_2_1\n",
      "save/restore_all_1_1\n",
      "w1_3\n",
      "w2_3\n",
      "bias/initial_value_2\n",
      "bias_3\n",
      "bias/Assign_2\n",
      "bias/read_2\n",
      "add_3\n",
      "op_to_restore_3\n",
      "init_3\n",
      "save/Const_3\n",
      "save/SaveV2/tensor_names_2\n",
      "save/SaveV2/shape_and_slices_2\n",
      "save/SaveV2_3\n",
      "save/control_dependency_3\n",
      "save/RestoreV2/tensor_names_2\n",
      "save/RestoreV2/shape_and_slices_2\n",
      "save/RestoreV2_3\n",
      "save/Assign_4\n",
      "save/restore_all_3\n",
      "Mul/y_2\n",
      "Mul_2\n",
      "w1_1_2\n",
      "w2_1_2\n",
      "bias_1/initial_value_2\n",
      "bias_1_2\n",
      "bias_1/Assign_2\n",
      "bias_1/read_2\n",
      "add_1_2\n",
      "op_to_restore_1_2\n",
      "init_1_2\n",
      "save/Const_1_2\n",
      "save/SaveV2_1/tensor_names_2\n",
      "save/SaveV2_1/shape_and_slices_2\n",
      "save/SaveV2_1_2\n",
      "save/control_dependency_1_2\n",
      "save/RestoreV2_1/tensor_names_2\n",
      "save/RestoreV2_1/shape_and_slices_2\n",
      "save/RestoreV2_1_2\n",
      "save/Assign_1_2\n",
      "save/Assign_2_2\n",
      "save/restore_all_1_2\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오고 operation과 layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model/my_test_model-1000\n",
      "120.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 현재 커널의 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('./my_test_model/my_test_model-1000.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./my_test_model/'))\n",
    "\n",
    "\n",
    "# Now, let's access and create placeholders variables and\n",
    "# create feed-dict to feed new data\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "feed_dict ={w1:13.0,w2:17.0}\n",
    "\n",
    "#Now, access the op that you want to run. \n",
    "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "#Add more to the current graph\n",
    "add_on_op = tf.multiply(op_to_restore,2)\n",
    "\n",
    "print (sess.run(add_on_op,feed_dict))\n",
    "#This will print 120.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
